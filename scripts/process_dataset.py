import argparse
import json
import multiprocessing
import os
import sys
import traceback
from pathlib import Path
from typing import Dict, List

import dgl
import joblib as J
import networkx as nx
import torch
from androguard.core.analysis.analysis import MethodAnalysis
from androguard.core.api_specific_resources import load_permission_mappings
from androguard.core.bytecodes.dvm import Instruction
from androguard.misc import AnalyzeAPK
from pygtrie import StringTrie

from process_api import get_inheritance_graph

attributes = ['external', 'entrypoint', 'native', 'public', 'static', 'codesize', 'api_package', 'opcodes']
package_directory = os.path.dirname(os.path.abspath(__file__))


def get_api_list() -> Dict[str, int]:
    """
    Get API List fetched from Android Project Website
    :return: Mapping from API name to its ID
    """
    apis = open(Path(package_directory).parent / "metadata" / "api.list").readlines()
    return {x.strip(): i for i, x in enumerate(apis)}


def get_api_trie() -> StringTrie:
    api_list = get_api_list()
    api_trie = StringTrie(separator='.')
    for k, v in api_list.items():
        api_trie[k] = v
    return api_trie


def get_opcode_mapping() -> Dict[str, int]:
    """
    Group opcodes and assign them an ID
    :return: Mapping from opcode group name to their ID
    """
    mapping = {x: i for i, x in enumerate(['nop', 'mov', 'return',
                                           'const', 'monitor', 'check-cast', 'instanceof', 'new',
                                           'fill', 'throw', 'goto/switch', 'cmp', 'if', 'unused',
                                           'arrayop', 'instanceop', 'staticop', 'invoke',
                                           'unaryop', 'binop', 'inline'])}
    mapping['invalid'] = -1
    return mapping


opcode_mapping = get_opcode_mapping()


def get_instruction_type(instr: Instruction) -> str:
    """
    Get instruction group name from instruction
    :param instr: DVM instruction
    :return: String containing ID of :instr:
    """
    value = instr.get_op_value()
    if 0x00 == value:
        return 'nop'
    elif 0x01 <= value <= 0x0D:
        return 'mov'
    elif 0x0E <= value <= 0x11:
        return 'return'
    elif 0x12 <= value <= 0x1C:
        return 'const'
    elif 0x1D <= value <= 0x1E:
        return 'monitor'
    elif 0x1F == value:
        return 'check-cast'
    elif 0x20 == value:
        return 'instanceof'
    elif 0x22 <= value <= 0x23:
        return 'new'
    elif 0x24 <= value <= 0x26:
        return 'fill'
    elif 0x27 == value:
        return 'throw'
    elif 0x28 <= value <= 0x2C:
        return 'goto/switch'
    elif 0x2D <= value <= 0x31:
        return 'cmp'
    elif 0x32 <= value <= 0x3D:
        return 'if'
    elif (0x3E <= value <= 0x43) or (value == 0x73) or (0x79 <= value <= 0x7A) or (0xE3 <= value <= 0xED):
        return 'unused'
    elif (0x44 <= value <= 0x51) or (value == 0x21):
        return 'arrayop'
    elif (0x52 <= value <= 0x5F) or (0xF2 <= value <= 0xF7):
        return 'instanceop'
    elif 0x60 <= value <= 0x6D:
        return 'staticop'
    elif (0x6E <= value <= 0x72) or (0x74 <= value <= 0x78) or (0xF0 == value) or (0xF8 <= value <= 0xFB):
        return 'invoke'
    elif 0x7B <= value <= 0x8F:
        return 'unaryop'
    elif 0x90 <= value <= 0xE2:
        return 'binop'
    elif 0xEE == value:
        return 'inline'
    else:
        return 'invalid'


def mapping_to_bitstring(mapping: List[int]) -> torch.Tensor:
    """
    Convert opcode mappings to bitstring
    :param mapping: List of IDs of opcode groups (present in an method)
    :return: Binary tensor of length `len(opcode_mapping)` with value 1 at positions specified by :poram mapping:
    """
    size = torch.Size([1, len(opcode_mapping) - 1])
    if len(mapping) > 0:
        indices = torch.LongTensor([[0, x] for x in mapping]).t()
        values = torch.ShortTensor([1] * len(mapping))
        tensor = torch.sparse.ShortTensor(indices, values, size)
    else:
        tensor = torch.sparse.ShortTensor(size)
    return tensor.to_dense()


def get_instruction_tensor(method: MethodAnalysis) -> torch.Tensor:
    """
    Node feature for internal method
    :param method:
    :return:
    """
    opcode_groups = set()
    if not method.is_external():
        for instr in method.get_method().get_instructions():
            instruction_type = get_instruction_type(instr)
            instruction_id = opcode_mapping[instruction_type]
            if instruction_id >= 0:
                opcode_groups.add(instruction_id)
    return mapping_to_bitstring(list(opcode_groups))


def get_api_package(method: MethodAnalysis, api_trie: StringTrie) -> int:
    """
    Node feature for external method
    :param method:
    :param api_trie:
    :return:
    """
    if method.is_external():
        name = str(method.class_name)[1:-1].replace('/', '.')
        return get_api_package_by_name(name, api_trie)


def get_api_package_by_name(name: str, api_trie: StringTrie) -> int:
    _, index = api_trie.longest_prefix(name)
    return index if index else -1


class APIConfig:
    def __init__(self, metadata_dir: Path):
        if not metadata_dir.exists():
            raise FileNotFoundError(f"{metadata_dir} doesn't exist")
        self.result = json.load(open(metadata_dir / "api_analysis/final_callbacks.json"))
        self.access_flags = json.load(open(metadata_dir / "api_analysis/access_flags.json"))
        self.method_names = json.load(open(metadata_dir / "api_analysis/method_names.json"))
        self.ig = nx.readwrite.json_graph.node_link_graph(
            json.load(open(metadata_dir / "api_analysis/inheritance_graph.json")))
        self.ag = nx.readwrite.json_graph.node_link_graph(
            json.load(open(metadata_dir / "api_analysis/argument_graph.json")))
        self.result_remapping = self._remap_result()
        self.registration_methods = set()
        self.permission_mapping = load_permission_mappings(apilevel=25)
        self.permission_to_int = {
            x: i for i, x in
            enumerate(sorted(set(sum(self.permission_mapping.values(), []))))
            if x.startswith("android.permission")
        }
        for x in self.result:
            for used_class in x['used_classes']:
                class_ = x['used_classes'][used_class]
                self.registration_methods.update(class_['registration_methods'])
        self.api_trie = get_api_trie()

    def _remap_result(self):
        result_remapping = {}
        result = list(self.result)
        for entry in result:
            callback_class = entry['callback_class']
            used_classes = entry['used_classes']
            for used_class in used_classes:
                registration_methods = used_classes[used_class]['registration_methods']
                mapping = used_classes[used_class]['used->callback mapping']
                if used_class not in result_remapping:
                    result_remapping[used_class] = {
                        'registration_methods': set(registration_methods),
                        'used->callback mapping': set(map(tuple, mapping)),
                        'callback_classes': {callback_class}
                    }
                else:
                    (result_remapping[used_class]['registration_methods']).update(registration_methods)
                    (result_remapping[used_class]['used->callback mapping']).update(map(tuple, mapping))
                    (result_remapping[used_class]['callback_classes']).add(callback_class)
        return result_remapping


class APKProcessor:

    def __init__(self, source_file: Path, api_config: APIConfig):
        if not source_file.exists():
            raise FileNotFoundError(f"{source_file} doesn't exist")
        if api_config is None:
            raise ValueError("api_config is None.")
        self.api_config = api_config
        try:
            _, _, self.dx = AnalyzeAPK(str(source_file))
        except:
            raise RuntimeError(f"Error while processing {source_file}")
        self.classes = set(map(lambda x: str(x), self.dx.classes.keys()))
        self.methods = set(map(lambda x: str(x.full_name), self.dx.methods.keys()))
        self.inheritance_graph = get_inheritance_graph(self.dx)
        # Features
        self.node_types = ['api_method', 'api_class', 'method', 'class', 'permission']
        self.node_features = {
            x: {} for x in self.node_types
            # Each feature is node name->feature mapping
        }
        self.node_to_int = {
            x: {} for x in self.node_types
            # Each mapping is node name->node ID mapping
        }
        # The graphs, in particular edges
        self.function_call_graph = {
            ('method', 'calls', 'method'): set(),
            ('method', 'calls', 'api_method'): set(),
            ('api_method', 'calls', 'api_method'): set(),
            ('method', 'parent_of', 'method'): set(),  # override by
            ('api_method', 'parent_of', 'method'): set(),
            ('api_method', 'parent_of', 'api_method'): set(),
            ('permission', 'used_by', 'api_method'): set(),
        }
        self.class_call_graph = {
            ('class', 'calls', 'class'): set(),
            ('class', 'calls', 'api_class'): set(),
            ('api_class', 'calls', 'api_class'): set(),
            ('class', 'parent_of', 'class'): set(),  # extends or implements
            ('api_class', 'parent_of', 'class'): set(),
            ('api_class', 'parent_of', 'api_class'): set(),
            ('permission', 'used_by', 'api_class'): set(),
        }

    def reduce_call_graph(self):
        for parent_class, child_class in self.inheritance_graph.edges:
            parent = self.dx.get_class_analysis(parent_class)
            child = self.dx.get_class_analysis(child_class)
            if not child or len(child.get_methods()) == 0:
                continue
            if not parent or parent.is_external():
                if any([x and x.is_external() for x in child.get_methods()]):
                    relation = self.class_call_graph[('api_class', 'parent_of', 'api_class')]
                else:
                    relation = self.class_call_graph[('api_class', 'parent_of', 'class')]
            else:
                relation = self.class_call_graph[('class', 'parent_of', 'class')]
            relation.add((parent_class, child_class))
        for key in self.function_call_graph:
            if 'parent_of' in key:
                continue
            updated_key = tuple(x.replace("method", "class") for x in key)
            for edges in self.function_call_graph[key]:
                src = edges[0].split(';')[0] + ';' if "permission" not in updated_key else edges[0]
                dest = edges[1].split(';')[0] + ';'
                self.class_call_graph[updated_key].add((src, dest))
        # Now time for feature aggregation
        # First we will do it for user classes
        for method, feature in self.node_features['method'].items():
            class_name = method.split(';')[0] + ';'
            if class_name not in self.node_features['class']:
                self.node_features['class'][class_name] = feature
            else:
                old_feature = self.node_features['class'][class_name]
                new_feature = old_feature | feature  # Index wise OR or tensors
                self.node_features['class'][class_name] = new_feature
        # Then for API classes
        for method, feature in self.node_features['api_method'].items():
            class_name = method.split(';')[0] + ';'
            if class_name not in self.node_features['api_class']:
                self.node_features['api_class'][class_name] = feature
            else:
                old_feature = self.node_features['api_class'][class_name]
                assert old_feature == feature  # API package should be same irrespective of method name

    def get_method_names(self, class_name):
        class_ = self.dx.get_class_analysis(class_name)
        method_names = set()
        if class_:
            method_names = {f'{x.name} {x.descriptor}': x.is_external() for x in class_.get_methods()}
        elif class_name in self.api_config.method_names:
            method_names = {x: True for x in self.api_config.method_names[class_name]}
        return method_names

    def process(self):
        used_registrations = self.api_config.registration_methods & self.methods
        registration_classes = {x.split(';')[0] + ';' for x in used_registrations}
        # All registration classes should be external
        # If not, make them so that analysis should not break :x
        for class_ in registration_classes:
            class_analysis = self.dx.get_class_analysis(class_)
            class_analysis.external = True
        assert all(map(lambda x: self.dx.get_class_analysis(x).is_external(), registration_classes))
        # First we shall add overriding relationships
        added_methods = set()
        for parent in self.inheritance_graph:
            # This is everywhere, so don't include!
            if parent == 'Ljava/lang/Object;':
                continue
            children = self.inheritance_graph[parent]
            parent_class = self.dx.get_class_analysis(parent)
            parent_method_names = self.get_method_names(parent)
            if len(parent_method_names) == 0:
                continue
            for child in children:
                child_method_names = self.get_method_names(child)
                common_methods = set(parent_method_names) & set(child_method_names)
                for common_method in common_methods:
                    parent_signature = f'{parent} {common_method}'
                    child_signature = f'{child} {common_method}'
                    if not parent_class or parent_class.is_external():
                        if child_method_names[common_method]:  # True => Child method is external
                            relation = self.function_call_graph[('api_method', 'parent_of', 'api_method')]
                        else:
                            relation = self.function_call_graph[('api_method', 'parent_of', 'method')]
                    else:
                        relation = self.function_call_graph[('method', 'parent_of', 'method')]
                    if parent_signature not in self.methods:
                        # That means we have loaded it from self.api_config.method_names
                        added_methods.add(parent_signature)
                    relation.add((parent_signature, child_signature))
        # Added methods are external, so add their feature also
        for added_method in added_methods:
            name = added_method.split(';')[0][1:].replace('/', '.')
            self.node_features['api_method'][added_method] = get_api_package_by_name(name, self.api_config.api_trie)
        # Then we shall add calling and permission relationships
        for method in self.dx.methods.values():
            class_name = str(method.class_name)
            method_name = str(method.full_name)
            if method.is_external():
                # We shall deal with the permissions now
                permissions = self.api_config.permission_mapping.get(
                    '-'.join([str(method.class_name), str(method.name), str(method.descriptor)]),
                    []
                )
                for permission in permissions:
                    permission_id = self.api_config.permission_to_int.get(permission, -1)
                    if permission_id < 0:
                        continue
                    self.function_call_graph[('permission', 'used_by', 'api_method')].add((permission, method_name))
                    # Add feature now
                    self.node_features['permission'][permission] = permission_id
                # If this method is a registration method,
                if method_name in used_registrations:
                    # It should be called somewhere!
                    if len(method.get_xref_from()) == 0:
                        continue
                    result_entry = self.api_config.result_remapping[class_name]
                    # method_name will be in result_entry['registration_methods']
                    # We shall add now add edges from api->api
                    for mapping in result_entry['used->callback mapping']:
                        used_method = mapping[0]
                        callback_method = mapping[1]
                        if used_method not in self.methods | added_methods:
                            # Set union is happening in condition!
                            # If used method is not in method list, we shall make registration as used method
                            used_method = method_name
                        if callback_method in self.methods:
                            self.function_call_graph[('api_method', 'calls', 'api_method')].add(
                                (used_method, callback_method)
                            )
                # Add feature now
                self.node_features['api_method'][method_name] = get_api_package(method, self.api_config.api_trie)
            else:
                # Now this is not an external method
                # Regular stuff now!
                called_methods = method.get_xref_to()
                for called_class, called_method, offset in called_methods:
                    if called_method.is_external():
                        relation = self.function_call_graph[('method', 'calls', 'api_method')]
                    else:
                        relation = self.function_call_graph[('method', 'calls', 'method')]
                    relation.add((method_name, str(called_method.full_name)))
                # Add a self-loop to make this node visible for features
                # self.function_call_graph[('method', 'calls', 'method')].add((method_name, method_name))
                # Add feature now
                self.node_features['method'][method_name] = get_instruction_tensor(method)
        # Now calculate class level call graph
        self.reduce_call_graph()

    def get_mapping(self, node_type, node_value):
        # Assert to if :|
        if node_value not in self.node_features[node_type]:
            return None
        if node_value not in self.node_to_int[node_type]:
            self.node_to_int[node_type][node_value] = len(self.node_to_int[node_type])
        return self.node_to_int[node_type][node_value]

    def export_heterograph(self, reduced=False):
        graph = self.class_call_graph if reduced else self.function_call_graph
        result_graph = {k: None for k in graph}
        for key, value in graph.items():
            mapped_src, mapped_dest = [], []
            src_type, dest_type = key[0], key[2]
            for edge in value:
                src, dest = edge
                src_map = self.get_mapping(src_type, src)
                dest_map = self.get_mapping(dest_type, dest)
                if src_map and dest_map:
                    mapped_src.append(src_map)
                    mapped_dest.append(dest_map)
            result_graph[key] = (torch.LongTensor(mapped_src), torch.LongTensor(mapped_dest))
        dgl_graph = dgl.heterograph(result_graph)
        node_data = {}
        for node_type in dgl_graph.ntypes:
            feature_vector = [None] * len(self.node_to_int[node_type])
            for node_name, node_index in self.node_to_int[node_type].items():
                feature = self.node_features[node_type][node_name]
                feature_vector[node_index] = feature
            if node_type == 'method' or node_type == 'class':
                node_data[node_type] = torch.stack(feature_vector).squeeze()
            else:
                node_data[node_type] = torch.Tensor(feature_vector)
        dgl_graph.ndata['features'] = node_data
        return dgl_graph


def process(config: APIConfig, source_file: Path, dest_dir: Path):
    """
    Process APK file and export call graph in DGL format
    :param config:
    :param source_file: Path of APK file
    :param dest_dir: Path of the directory to store processed graph
    :return: None
    """
    try:
        processor = APKProcessor(source_file, config)
        processor.process()
        function_dg = processor.export_heterograph()
        class_dg = processor.export_heterograph(reduced=True)
        file_name = source_file.stem
        dgl.data.utils.save_graphs(str(dest_dir / f"{file_name}.fcg"), [function_dg])
        dgl.data.utils.save_graphs(str(dest_dir / f"{file_name}.rfcg"), [class_dg])
        json.dump(processor.node_to_int, open(dest_dir / f"{file_name}.map"))
        print(f"Processed {source_file}")
    except:
        print(f"Error while processing {source_file}")
        traceback.print_exception(*sys.exc_info())
        return


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Preprocess APK Dataset into Graphs')
    parser.add_argument(
        '--source-dir',
        help='The directory containing apks',
        required=True
    )
    parser.add_argument(
        '--dest-dir',
        help='The directory to store processed graphs',
        required=True
    )
    parser.add_argument(
        '--metadata-dir',
        help='The directory pointing to metadata. Must contain api_analysis/',
        required=True
    )
    parser.add_argument(
        '--override',
        help='Override existing processed files',
        action='store_true'
    )
    parser.add_argument(
        '--dry',
        help='Run without actual processing',
        action='store_true'
    )
    parser.add_argument(
        '--n-jobs',
        default=multiprocessing.cpu_count(),
        help='Number of jobs to be used for processing'
    )
    args = parser.parse_args()
    source_dir = Path(args.source_dir)
    if not source_dir.exists():
        raise FileNotFoundError(f'{source_dir} not found')
    dest_dir = Path(args.dest_dir)
    if not dest_dir.exists():
        raise FileNotFoundError(f'{dest_dir} not found')
    metadata_dir = Path(args.metadata_dir)
    if not metadata_dir.exists():
        raise FileNotFoundError(f'{metadata_dir} not found')
    config = APIConfig(metadata_dir)
    n_jobs = args.n_jobs
    if n_jobs < 2:
        print(f"n_jobs={n_jobs} is too less. Switching to number of CPUs in this machine instead")
        n_jobs = multiprocessing.cpu_count()
    files = [x for x in source_dir.iterdir() if x.is_file()]
    source_files = set([x.stem for x in files])
    dest_files = set([x.stem for x in dest_dir.iterdir() if x.is_file()])
    unprocessed = [source_dir / f'{x}.apk' for x in source_files - dest_files]
    print(f"Only {len(unprocessed)} out of {len(source_files)} remain to be processed")
    if args.override:
        print(f"--override specified. Ignoring {len(source_files) - len(unprocessed)} processed files")
        unprocessed = [source_dir / f'{x}.apk' for x in source_files]
    print(f"Starting dataset processing with {n_jobs} Jobs")
    if not args.dry:
        J.Parallel(n_jobs=n_jobs)(J.delayed(process)(config, x, dest_dir) for x in unprocessed)
    print("DONE")

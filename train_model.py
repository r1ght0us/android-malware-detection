import os
from pathlib import Path
from typing import Any, Dict

import hydra
import datetime
from omegaconf import DictConfig
from pytorch_lightning import Trainer
from pytorch_lightning.callbacks import ModelCheckpoint

from core.data_module import MalwareDataModule
from core.model import MalwareDetector
from core.utils import plot_roc


@hydra.main(config_path="config", config_name="conf")
def train_model(cfg: DictConfig) -> None:
    cwd = Path(hydra.utils.get_original_cwd())
    dataset_directory = cwd / Path(cfg['dataloader']['data_dir'])
    if not dataset_directory.exists():
        raise FileNotFoundError(f'{dataset_directory} does not exist. Could not read data from it.')
    feature_list = cfg['features']['attributes']
    data_module = MalwareDataModule(
        data_dir=dataset_directory,
        batch_size=cfg['dataloader']['batch_size'],
        split_ratios=[0.6, 0.2, 0.2],
        cache=cfg['dataloader']['cache'],
        pin_memory=cfg['dataloader']['pin_memory'],
        num_workers=cfg['dataloader']['num_workers'],
        attribute_list=feature_list
    )

    convolution_count = cfg['model']['convolution_count']
    convolution_dimensions = [64, 32, 16][:min(convolution_count, 3)]
    readout_weights = cfg['features']['readout_weights']
    input_size = cfg['features']['size']
    readout_type = cfg['features']['readout_type']
    model = MalwareDetector(
        input_dimension=input_size,
        convolution_algorithm=cfg['model']['convolution_algorithm'],
        convolution_dimensions=convolution_dimensions,
        readout_weights=readout_weights,
        readout_type=readout_type
    )

    current_date = datetime.datetime.now().strftime("%Y%m%d")
    checkpoint_callback = ModelCheckpoint(
        dirpath=os.getcwd(),
        filename=str(current_date + '-{epoch:02d}-{val_loss:.2f}.pt'),
        monitor='val_loss',
        mode='min',
        save_last=True
    )
    trainer_kwargs = dict(cfg['trainer'])
    force_retrain = cfg.get('force_retrain', False)
    if Path('last.ckpt').exists() and not force_retrain:
        trainer_kwargs['resume_from_checkpoint'] = 'last.ckpt'
    trainer = Trainer(callbacks=[checkpoint_callback], **trainer_kwargs)
    testing = cfg.get('testing', False)
    if not testing:
        trainer.fit(model, datamodule=data_module)
    else:
        best_checkpoints = [x for x in Path(os.getcwd()).glob("*ckpt") if x.name != "last.ckpt"]
        if len(best_checkpoints) == 0:
            print("No checkpoints found. No test is performed")
            return
        print(f"Found {len(best_checkpoints)} checkpoints. Using {best_checkpoints[0]}")
        trainer.test(model, datamodule=data_module, verbose=True)
        (tpr, fpr, thresholds), auc = model.auc_roc.compute()
        plot_roc(tpr.cpu(), fpr.cpu(), thresholds.cpu())
        print("AUC =", auc)


if __name__ == '__main__':
    train_model()

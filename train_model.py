import datetime
import os
from pathlib import Path

import hydra
from omegaconf import DictConfig
from pytorch_lightning import Trainer
from pytorch_lightning.callbacks import ModelCheckpoint

from core.data_module import MalwareDataModule
from core.model import MalwareDetector
from core.utils import plot_roc


@hydra.main(config_path="config", config_name="conf")
def train_model(cfg: DictConfig) -> None:
    cwd = Path(hydra.utils.get_original_cwd())
    data_type = cfg['dataloader']['data_type']

    if data_type != 'fcg' or data_type != 'rfcg':
        raise ValueError(f"Invalid data type specified - {data_type}. Must be one of 'fcg' or 'rfcg'")

    train_directory = cwd / Path(cfg['dataloader']['train_dir']) / data_type
    test_directory = cwd / Path(cfg['dataloader']['test_dir']) / data_type

    if not train_directory.exists():
        raise FileNotFoundError(f'{train_directory} does not exist. Could not read data from it.')

    if not test_directory.exists():
        raise FileNotFoundError(f'{test_directory} does not exist. Could not read data from it.')

    data_module = MalwareDataModule(
        train_dir=train_directory,
        test_dir=test_directory,
        batch_size=cfg['dataloader']['batch_size'],
        split_ratios=(0.75, 0.25),
        pin_memory=cfg['dataloader']['pin_memory'],
        num_workers=cfg['dataloader']['num_workers'],
    )

    convolution_count = cfg['model']['convolution_count']
    model = MalwareDetector(
        convolution_count=convolution_count,
        data_type=data_type,
        consider_nodes=cfg['node_configuration']['nodes']
    )

    current_date = datetime.datetime.now().strftime("%Y%m%d")
    checkpoint_callback = ModelCheckpoint(
        dirpath=os.getcwd(),
        filename=str(current_date + '-{epoch:02d}-{val_loss:.2f}.pt'),
        monitor='val_loss',
        mode='min',
        save_last=True
    )
    trainer_kwargs = dict(cfg['trainer'])
    force_retrain = cfg.get('force_retrain', False)
    if Path('last.ckpt').exists() and not force_retrain:
        trainer_kwargs['resume_from_checkpoint'] = 'last.ckpt'
    trainer = Trainer(callbacks=[checkpoint_callback], **trainer_kwargs)
    testing = cfg.get('testing', False)
    if not testing:
        trainer.fit(model, datamodule=data_module)
    else:
        best_checkpoints = [x for x in Path(os.getcwd()).glob("*ckpt") if x.name != "last.ckpt"]
        if len(best_checkpoints) == 0:
            print("No checkpoints found. No test is performed")
            return
        print(f"Found {len(best_checkpoints)} checkpoints. Using {best_checkpoints[0]}")
        trainer.test(model, datamodule=data_module, verbose=True)


if __name__ == '__main__':
    train_model()
